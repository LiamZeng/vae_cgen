{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Input, Conv2D, Flatten, Dense, Conv2DTranspose, Reshape, Lambda, Activation, BatchNormalization, ReLU, Dropout\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint \n",
    "from keras.utils import plot_model\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "\n",
    "DATA_FOLDER = '../input/celeba-dataset/img_align_celeba/img_align_celeba/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = np.array(glob(os.path.join(DATA_FOLDER, '*.jpg')))\n",
    "NUM_IMAGES = len(filenames)\n",
    "print(\"Total number of images : \" + str(NUM_IMAGES))\n",
    "# prints : Total number of images : 202599\n",
    " \n",
    "INPUT_DIM = (128,128,3) # Image dimension\n",
    "BATCH_SIZE = 128\n",
    "# train set num is 162770\n",
    " \n",
    "data_flow = ImageDataGenerator(rescale=1./255).flow_from_directory('../input/celeba-dataset/img_align_celeba/', \n",
    "                                                                   target_size = (64,64),\n",
    "                                                                   batch_size = BATCH_SIZE,\n",
    "                                                                   shuffle = True,\n",
    "                                                                   class_mode = 'input',\n",
    "                                                                   subset = 'training'\n",
    "                                                                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a sampling layer\n",
    "from tensorflow.keras.layers import Layer\n",
    "class reparameterize(Layer):\n",
    "    \"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\"\"\"\n",
    "    def call(self, inputs):\n",
    "        mean, logvar = inputs\n",
    "        batch = tf.shape(mean)[0]\n",
    "        dim = tf.shape(mean)[1]\n",
    "        eps = tf.keras.backend.random_normal(shape=(batch, dim))\n",
    "        return eps * tf.exp(logvar * .5) + mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder\n",
    "input_shape = (64, 64, 3)\n",
    "kernel_size = 5\n",
    "latent_dim = 512\n",
    "image_size = 64 # square, original to be resized\n",
    "crop_size = 148 # center crop to this size per dimension\n",
    "batch_size = 128\n",
    "gamma_init = tf.random_normal_initializer(1., 0.02)\n",
    "\n",
    "# First build the Encoder Model part\n",
    "inputs = Input(shape=input_shape, name='encoder_input')\n",
    "x = Conv2D(filters=64, kernel_size=kernel_size, strides=2, padding='same', name='conv1')(inputs)\n",
    "x = BatchNormalization(gamma_initializer=gamma_init, trainable=True)(x)\n",
    "x = ReLU()(x)\n",
    "x = Conv2D(filters=128, kernel_size=kernel_size, strides=2, padding='same', name='conv2')(x)\n",
    "x = BatchNormalization(gamma_initializer=gamma_init, trainable=True)(x)\n",
    "x = ReLU()(x)\n",
    "x = Conv2D(filters=256, kernel_size=kernel_size, strides=2, padding='same', name='conv3')(x)\n",
    "x = BatchNormalization(gamma_initializer=gamma_init, trainable=True)(x)\n",
    "x = ReLU()(x)\n",
    "x = Conv2D(filters=512, kernel_size=kernel_size, strides=2, padding='same', name='conv4')(x)\n",
    "x = BatchNormalization(gamma_initializer=gamma_init, trainable=True)(x)\n",
    "x = ReLU()(x)\n",
    "\n",
    "shape = K.int_shape(x)\n",
    "\n",
    "x = Flatten()(x)\n",
    "mean = Dense(latent_dim, name=\"z_mean\")(x)\n",
    "logvar = Dense(latent_dim, name=\"z_log_var\")(x)\n",
    "z = reparameterize()([mean, logvar])\n",
    "\n",
    "# Instantiate Encoder Model\n",
    "encoder = Model(inputs, [z, mean, logvar], name='encoder')\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decoder\n",
    "latent_inputs = Input(shape=(latent_dim,), name='decoder_input')\n",
    "x = Dense(shape[1] * shape[2] * shape[3] * 2)(latent_inputs)\n",
    "x = Reshape((shape[1]*2, shape[2]*2, shape[3]//2), name='h0_reshape')(x)\n",
    "x = BatchNormalization(gamma_initializer=gamma_init, trainable=True)(x)\n",
    "x = ReLU()(x)\n",
    "\n",
    "x = Conv2DTranspose(filters=256, kernel_size=5, strides=2, padding='same')(x)\n",
    "x = BatchNormalization(gamma_initializer=gamma_init, trainable=True)(x)\n",
    "x = ReLU()(x)\n",
    "x = Conv2DTranspose(filters=128, kernel_size=5, strides=2, padding='same')(x)\n",
    "x = BatchNormalization(gamma_initializer=gamma_init, trainable=True)(x)\n",
    "x = ReLU()(x)\n",
    "x = Conv2DTranspose(filters=64, kernel_size=5, strides=2, padding='same')(x)\n",
    "x = BatchNormalization(gamma_initializer=gamma_init, trainable=True)(x)\n",
    "x = ReLU()(x)\n",
    "x = Conv2DTranspose(filters=3, kernel_size=5, strides=1, padding='same')(x)\n",
    "outputs = Activation('tanh', name='decoder_output')(x)\n",
    "\n",
    "# Instantiate Decoder Model\n",
    "decoder = Model(latent_inputs, outputs, name='decoder')\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(Model):\n",
    "    def __init__(self, encoder, latent_dim, decoder, **kwargs):\n",
    "        super(VAE, self).__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.cf_layer = Dense(units=latent_dim, kernel_initializer=tf.constant_initializer(np.eye(latent_dim)))\n",
    "        # self.cf_layer = Sequential(\n",
    "        #     [\n",
    "        #     Input(shape=(latent_dim,)),\n",
    "        #     Dense(32, activation=\"relu\"),\n",
    "        #     Dense(latent_dim),\n",
    "        #     ]\n",
    "        # )\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def train_step(self, data):\n",
    "        if isinstance(data, tuple):\n",
    "            data = data[0]\n",
    "        with tf.GradientTape() as tape:\n",
    "            z, mean, logvar = encoder(data)\n",
    "            reconstruction = decoder(z)\n",
    "            reconstruction_loss = tf.reduce_mean(\n",
    "                tf.keras.losses.binary_crossentropy(data, reconstruction)\n",
    "            )\n",
    "            reconstruction_loss *= 64 * 64\n",
    "            kl_loss = 1 + logvar - tf.square(mean) - tf.exp(logvar)\n",
    "            kl_loss = tf.reduce_mean(kl_loss)\n",
    "#             kl_loss = tf.reduce_sum(kl_loss)\n",
    "            kl_loss *= -0.5\n",
    "#             LOSS_FACTOR = 10000\n",
    "            total_loss = reconstruction_loss + kl_loss\n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "        return {\n",
    "            \"loss\": total_loss,\n",
    "            \"reconstruction_loss\": reconstruction_loss,\n",
    "            \"kl_loss\": kl_loss,\n",
    "        }\n",
    "\n",
    "    def call(self, inputs):\n",
    "      z, mean, logvar = encoder(inputs)\n",
    "      return decoder(z)\n",
    "\n",
    "    def cf(self, inputs):\n",
    "      z, mean, logvar = encoder(inputs)\n",
    "      return decoder(self.cf_layer(z))\n",
    "\n",
    "    @tf.function\n",
    "    def sample(self, eps=None):\n",
    "      if eps is None:\n",
    "        eps = tf.random.normal(shape=(100, latent_dim))\n",
    "      return tf.sigmoid(self.decoder(eps))\n",
    "\n",
    "# Instantiate vae\n",
    "vae = VAE(encoder, latent_dim, decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae.load_weights('../input/checkpoint-30/CELEBVAE_30.tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pic_size=64\n",
    "pic_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = cv2.imread('../input/celeba-dataset/img_align_celeba/img_align_celeba/000001.jpg')\n",
    "temp = cv2.cvtColor(temp, cv2.COLOR_BGR2RGB)\n",
    "temp = cv2.resize(temp, (pic_size,pic_size)).astype('float32') / 255.\n",
    "plt.imshow(temp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = temp[np.newaxis, :]\n",
    "p = vae(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = p[0]\n",
    "b = K.eval(b)\n",
    "plt.imshow(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae.compile(optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae.fit_generator(data_flow, epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae.save_weights(\"cgen_pretrain_vae_400.tf\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
