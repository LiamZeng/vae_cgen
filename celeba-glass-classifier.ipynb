{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport cv2 \nimport seaborn as sns\nfrom matplotlib import pyplot as plt\n\nfrom IPython.core.display import display, HTML\nfrom PIL import Image\nfrom io import BytesIO\nimport base64\n\nimport os\nimport tensorflow as tf\nfrom tensorflow.keras.models import Model, Sequential\nfrom tensorflow.keras.layers import Dense, Activation, Input, BatchNormalization, ReLU, AveragePooling2D\nfrom tensorflow.keras.layers import Conv2D, Flatten, Dropout, UpSampling2D\nfrom tensorflow.keras.layers import Lambda, Subtract, Add\nfrom tensorflow.keras.layers import Reshape, Conv2DTranspose\nfrom tensorflow.keras.optimizers import RMSprop, Adam, SGD\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.models import load_model\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\nfrom keras.utils import np_utils\n\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# set variables \nmain_folder = '../input/celeba-dataset/'\nimages_folder = main_folder + 'img_align_celeba/img_align_celeba/'\nEXAMPLE_PIC = images_folder + '000506.jpg'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# import the data set that include the attribute for each picture\ndf_attr = pd.read_csv(main_folder + 'list_attr_celeba.csv')\ndf_attr.set_index('image_id', inplace=True)\ndf_attr.replace(to_replace=-1, value=0, inplace=True) #replace -1 by 0\ndf_attr.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"glass = df_attr[\"Eyeglasses\"]\n# In gender array 0-no glass while 1-glass\nglass.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.title('yes or no glasses')\nsns.countplot(y='Eyeglasses', data=df_attr, color=\"c\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_partition = pd.read_csv(main_folder + 'list_eval_partition.csv')\n# df_partition.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_partition['partition'].value_counts().sort_index()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_partition.set_index('image_id', inplace=True)\ndf_par_attr = df_partition.join(glass, how='inner')\ndf_par_attr.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def load_reshape_img(fname):\n    x = cv2.imread(fname)\n    x = cv2.cvtColor(x, cv2.COLOR_BGR2RGB)\n    x = cv2.resize(x, (64,64)).astype('float32') / 255.\n    x = x.reshape((1,) + x.shape)\n\n    return x\n\n\ndef generate_df(partition, attr, num_samples):\n    '''\n    partition\n        0 -> train\n        1 -> validation\n        2 -> test\n    \n    '''\n    \n    df_ = df_par_attr[(df_par_attr['partition'] == partition) \n                           & (df_par_attr[attr] == 0)].sample(int(num_samples/2))\n    df_ = pd.concat([df_,\n                      df_par_attr[(df_par_attr['partition'] == partition) \n                                  & (df_par_attr[attr] == 1)].sample(int(num_samples/2))])\n\n    # for Train and Validation\n    if partition != 2:\n        x_ = np.array([load_reshape_img(images_folder + fname) for fname in df_.index])\n        x_ = x_.reshape(x_.shape[0], 64, 64, 3)\n        y_ = np_utils.to_categorical(df_[attr],2)\n    # for Test\n    else:\n        x_ = []\n        y_ = []\n\n        for index, target in df_.iterrows():\n            im = cv2.imread(images_folder + index)\n            im = cv2.resize(cv2.cvtColor(im, cv2.COLOR_BGR2RGB), (IMG_WIDTH, IMG_HEIGHT)).astype(np.float32) / 255.0\n            im = np.expand_dims(im, axis =0)\n            x_.append(im)\n            y_.append(target[attr])\n\n    return x_, y_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"TRAINING_SAMPLES = 10000\nVALIDATION_SAMPLES = 2000\nIMG_WIDTH = 64\nIMG_HEIGHT = 64\n\nx_train, y_train = generate_df(0, 'Eyeglasses', TRAINING_SAMPLES)\nx_valid, y_valid = generate_df(1, 'Eyeglasses', VALIDATION_SAMPLES)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"count = 0\nfor i in range(10000):\n    if (y_train[i]==np.array([1,0])).all():\n        count += 1\nprint(x_train.shape)\ncount","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"input_shape = (IMG_WIDTH, IMG_HEIGHT, 3)\nkernel_size = 5\ngamma_init = tf.random_normal_initializer(1., 0.02)\n\ninputs = Input(shape=input_shape, name='classifier_input')\nx = Conv2D(filters=64, kernel_size=kernel_size, strides=2, padding='same')(inputs)\nx = BatchNormalization(gamma_initializer=gamma_init, trainable=True)(x)\nx = ReLU()(x)\nx = Conv2D(filters=128, kernel_size=kernel_size, strides=2, padding='same')(x)\nx = BatchNormalization(gamma_initializer=gamma_init, trainable=True)(x)\nx = ReLU()(x)\nx = Conv2D(filters=256, kernel_size=kernel_size, strides=2, padding='same')(x)\nx = BatchNormalization(gamma_initializer=gamma_init, trainable=True)(x)\nx = ReLU()(x)\nx = Flatten()(x)\nx = Dense(512, activation='relu')(x)\nx = Dense(units=1, activation = 'sigmoid')(x)\n\nclassifier = Model(inputs, x, name='classifier')\n# classifier.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classifier = load_model('../input/glass-classifier/glass_cf_15_sigmoid.tf')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classifier.compile(loss='bce', optimizer='adam')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size = 128\n\n# SIGMOID\ny_train_sigmoid = np.array([np.argmax(one_hot)for one_hot in y_train])\ny_valid_sigmoid = np.array([np.argmax(one_hot)for one_hot in y_valid])\n\n\ntrain_datagen =  ImageDataGenerator()\ntrain_datagen.fit(x_train)\ntrain_generator = train_datagen.flow(\nx_train, y_train_sigmoid,\nbatch_size=batch_size,\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hist = classifier.fit_generator(train_generator\n                     , validation_data = (x_valid, y_valid_sigmoid)\n                      , steps_per_epoch= TRAINING_SAMPLES/batch_size\n                      , epochs= 15\n                    )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(18, 4))\nplt.plot(hist.history['loss'], label = 'train')\nplt.plot(hist.history['val_loss'], label = 'valid')\nplt.legend()\nplt.title('Loss Function')\nplt.savefig('loss.pdf')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_img = load_reshape_img(images_folder+'200041.jpg')\nplt.imshow(test_img[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(classifier(test_img))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classifier.save(\"glass_cf_15_sigmoid.tf\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}